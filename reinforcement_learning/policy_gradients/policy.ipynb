{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(env, nb_episodes, alpha=0.000045, gamma=0.98):\n",
    "    \"\"\"\n",
    "    Train\n",
    "    \"\"\"\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "    weight = np.zeros((state_size, action_size))\n",
    "    all_scores = []\n",
    "\n",
    "    for episode in range(nb_episodes):\n",
    "        state = env.reset()[None, :]\n",
    "        done = False\n",
    "        score = 0\n",
    "        gradients = []\n",
    "        rewards = []\n",
    "\n",
    "        while not done:\n",
    "            state_matrix = np.reshape(state, [1, -1])\n",
    "            action, gradient = policy_gradient(state_matrix, weight)\n",
    "\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            weight += alpha * gamma**episode * reward * gradient\n",
    "\n",
    "            gradients.append(gradient)\n",
    "            rewards.append(reward)\n",
    "\n",
    "            state = new_state\n",
    "            score += reward\n",
    "\n",
    "        rewards = np.array(rewards)\n",
    "\n",
    "        for i in range(len(gradients)):\n",
    "            learning = (alpha * gradients[i])\n",
    "            discount = sum(gamma ** rewards[i:] * rewards[i:])\n",
    "            weight += learning * discount\n",
    "\n",
    "        print(f\"Episode: {episode + 1}, Score: {score}\")\n",
    "\n",
    "        all_scores.append(score)\n",
    "\n",
    "    return all_scores\n",
    "\n",
    "\n",
    "def policy(matrix, weight):\n",
    "    \"\"\"\n",
    "    Create Policy\n",
    "    \"\"\"\n",
    "    z = np.dot(matrix, weight)\n",
    "    exp_z = np.exp(z)\n",
    "    policy = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    return policy\n",
    "\n",
    "\n",
    "def policy_gradient(state, weight):\n",
    "    \"\"\"\n",
    "    Policy Gradient\n",
    "    \"\"\"\n",
    "    policy_probs = policy(state, weight)\n",
    "    action = np.random.choice(len(policy_probs[0]), p=policy_probs[0])\n",
    "\n",
    "    s = policy_probs.reshape(-1, 1)\n",
    "\n",
    "    soft = (np.diagflat(s) - np.dot(s, s.T))[action, :]\n",
    "\n",
    "    log = soft / policy_probs[0, action]\n",
    "\n",
    "    gradient = state.T.dot(log[None, :])\n",
    "\n",
    "    return action, gradient\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
